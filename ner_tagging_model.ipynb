{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikun\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 71ms/step - accuracy: 0.7818 - loss: 1.8739 - val_accuracy: 0.9458 - val_loss: 0.7508\n",
      "Epoch 2/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 66ms/step - accuracy: 0.9677 - loss: 0.3715 - val_accuracy: 0.9710 - val_loss: 0.5719\n",
      "Epoch 3/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 63ms/step - accuracy: 0.9901 - loss: 0.0975 - val_accuracy: 0.9746 - val_loss: 0.5435\n",
      "Epoch 4/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 63ms/step - accuracy: 0.9947 - loss: 0.0430 - val_accuracy: 0.9757 - val_loss: 0.6055\n",
      "Epoch 5/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 64ms/step - accuracy: 0.9966 - loss: 0.0235 - val_accuracy: 0.9785 - val_loss: 0.6513\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step\n",
      "Precision: 93.45%\n",
      "Recall: 89.58%\n",
      "F1-Score: 91.03%\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 9, does not match size of target_names, 10. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 120\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1-Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtag2idx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:2648\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2642\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2643\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2644\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[0;32m   2645\u001b[0m             )\n\u001b[0;32m   2646\u001b[0m         )\n\u001b[0;32m   2647\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2648\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2649\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2650\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2651\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[0;32m   2652\u001b[0m         )\n\u001b[0;32m   2653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2654\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[1;31mValueError\u001b[0m: Number of classes, 9, does not match size of target_names, 10. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, TimeDistributed, Bidirectional, Dropout, SpatialDropout1D\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "def load_conll_data(filepath):\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    \n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.strip() == '':\n",
    "                if sentence:\n",
    "                    sentences.append(sentence)\n",
    "                    sentence = []\n",
    "            else:\n",
    "                word, pos, chunk, ner = line.strip().split()\n",
    "                sentence.append((word, pos, ner))\n",
    "    if sentence:\n",
    "        sentences.append(sentence)\n",
    "        \n",
    "    return sentences\n",
    "\n",
    "train_file = r\"D:\\SIH_POC_MODEL\\Nikunj Dataset Train.txt\"\n",
    "test_file = r\"D:\\SIH_POC_MODEL\\Nikunj Dataset Test.txt\"  \n",
    "\n",
    "train_sentences = load_conll_data(train_file)\n",
    "test_sentences = load_conll_data(test_file)\n",
    "\n",
    "train_words = [[word for word, _, ner in sentence] for sentence in train_sentences]\n",
    "train_labels = [[ner for _, _, ner in sentence] for sentence in train_sentences]\n",
    "\n",
    "test_words = [[word for word, _, ner in sentence] for sentence in test_sentences]\n",
    "test_labels = [[ner for _, _, ner in sentence] for sentence in test_sentences]\n",
    "\n",
    "all_words = set([word for sentence in train_words for word in sentence])\n",
    "all_tags = set([tag for tags in train_labels for tag in tags])\n",
    "\n",
    "word2idx = {word: idx + 2 for idx, word in enumerate(all_words)}\n",
    "word2idx['PAD'] = 0\n",
    "word2idx['UNK'] = 1\n",
    "\n",
    "tag2idx = {tag: idx + 1 for idx, tag in enumerate(all_tags)}\n",
    "tag2idx['PAD'] = 0\n",
    "\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "idx2tag = {idx: tag for tag, idx in tag2idx.items()}\n",
    "\n",
    "MAX_LEN = 50\n",
    "\n",
    "def preprocess(sentences, labels):\n",
    "    X = [[word2idx.get(word, word2idx['UNK']) for word in sentence] for sentence in sentences]\n",
    "    X = pad_sequences(X, maxlen=MAX_LEN, padding='post')\n",
    "\n",
    "    y = [[tag2idx[tag] for tag in label] for label in labels]\n",
    "    y = pad_sequences(y, maxlen=MAX_LEN, padding='post')\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train_raw = preprocess(train_words, train_labels)\n",
    "X_test, y_test_raw = preprocess(test_words, test_labels)\n",
    "\n",
    "flattened_labels = np.concatenate(y_train_raw)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(flattened_labels), y=flattened_labels)\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "y_train = [to_categorical(i, num_classes=len(tag2idx)) for i in y_train_raw]\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "y_test = [to_categorical(i, num_classes=len(tag2idx)) for i in y_test_raw]\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "def create_sample_weights(y_raw, class_weight_dict):\n",
    "    sample_weights = np.ones((y_raw.shape[0], y_raw.shape[1]))\n",
    "    \n",
    "    for i in range(y_raw.shape[0]):\n",
    "        for j in range(y_raw.shape[1]):\n",
    "            tag_idx = y_raw[i][j]\n",
    "            if tag_idx != tag2idx['PAD']:\n",
    "                sample_weights[i][j] = class_weight_dict[tag_idx]\n",
    "    \n",
    "    return sample_weights\n",
    "\n",
    "sample_weights = create_sample_weights(y_train_raw, class_weight_dict)\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=len(word2idx), output_dim=100, input_length=MAX_LEN),\n",
    "    SpatialDropout1D(0.1),\n",
    "    Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1)),\n",
    "    TimeDistributed(Dense(len(tag2idx), activation=\"softmax\"))\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=5, validation_split=0.1, verbose=1, sample_weight=sample_weights)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=-1)\n",
    "y_test_true = np.argmax(y_test, axis=-1)\n",
    "\n",
    "y_pred_flat = y_pred.flatten()\n",
    "y_test_flat = y_test_true.flatten()\n",
    "\n",
    "mask = y_test_flat != tag2idx['PAD']\n",
    "y_pred_flat = y_pred_flat[mask]\n",
    "y_test_flat = y_test_flat[mask]\n",
    "\n",
    "precision = precision_score(y_test_flat, y_pred_flat, average='weighted')\n",
    "recall = recall_score(y_test_flat, y_pred_flat, average='weighted')\n",
    "f1 = f1_score(y_test_flat, y_pred_flat, average='weighted')\n",
    "\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1-Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "print(classification_report(y_test_flat, y_pred_flat, target_names=list(tag2idx.keys())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
